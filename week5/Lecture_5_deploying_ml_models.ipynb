{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14111bc0-a03f-4e9e-b1f2-182eee5e87a7",
   "metadata": {},
   "source": [
    "# Deploying Machine Learning Models\n",
    "\n",
    "* Train a model\n",
    "* Save the model\n",
    "* Use the model in a web service\n",
    "\n",
    "![Overview](Screenshot_1.png)\n",
    "\n",
    "**Code from previous weeks to train the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad5428-75b5-4085-b2e8-4d7a49a3700c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce0b80b-d06d-45ce-8bf6-d6a781676d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79a796-a520-4c45-87cf-2ff157caef6e",
   "metadata": {},
   "source": [
    "## Read and prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0c49ee-9e56-4dd4-8829-d3d9e2d8202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "\n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(' ', '_')\n",
    "\n",
    "df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')\n",
    "df.totalcharges = df.totalcharges.fillna(0)\n",
    "\n",
    "df.churn = (df.churn == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d196b1b-c915-4f71-9d32-a130711f1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5142c2-1657-420c-ae4a-7375fa018fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "\n",
    "categorical = [\n",
    "    'gender',\n",
    "    'seniorcitizen',\n",
    "    'partner',\n",
    "    'dependents',\n",
    "    'phoneservice',\n",
    "    'multiplelines',\n",
    "    'internetservice',\n",
    "    'onlinesecurity',\n",
    "    'onlinebackup',\n",
    "    'deviceprotection',\n",
    "    'techsupport',\n",
    "    'streamingtv',\n",
    "    'streamingmovies',\n",
    "    'contract',\n",
    "    'paperlessbilling',\n",
    "    'paymentmethod',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c711340-ba08-44d4-ac04-ee787aded433",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec4c9051-cf60-4d1d-8b3b-95553b7b0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d33dfe-15ac-4962-b8b4-eabe169d9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f05b4c-3d7a-4902-ba63-dfbbcfa3f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15b1f7e0-f9da-4fc0-bf34-aa8e47185803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0 0.840 +- 0.008\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.churn.values\n",
    "    y_val = df_val.churn.values\n",
    "\n",
    "    dv, model = train(df_train, y_train, C=C)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "\n",
    "print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eefcd569-b77e-40cb-9230-1319f214552d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8420689059666695,\n",
       " 0.8455854357038802,\n",
       " 0.8325025085289987,\n",
       " 0.8301724275756219,\n",
       " 0.8510401305261838]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5df43d19-d828-453e-8559-af2f55658fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8572386167896259"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model = train(df_full_train, df_full_train.churn.values, C=1.0)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "\n",
    "y_test = df_test.churn.values\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6dc94b-200e-44ca-8d68-b3ee1594eee0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Saving and Loading the Model\n",
    "\n",
    "* Save the model to pickle\n",
    "* Load the model from pickle\n",
    "* Turn our model into a Python script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d2eec-2d92-4ec1-95f3-d723a5bf886a",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Use library \"pickle\" to write our model into a file \n",
    "* Libary to dÂ¿save binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f2878d0-a1dd-4c24-8911-95454b7bce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a037ab5-66c8-4c37-ae10-caa48b8c9b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_C=1.0.bin'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = f\"model_C={C}.bin\"\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c886f5dd-8e38-4769-a37a-6011b400b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a binary file\n",
    "f_out = open(output_file, \"wb\")\n",
    "# save the model and the dictionary vectorizer (we need that in order to run the model)\n",
    "pickle.dump((dv, model), f_out)\n",
    "# close the file\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22b75b3c-3e1b-40b6-998f-fb0942d187dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative\n",
    "# this ensures that the file is closed, when the \"with\" statement is left\n",
    "with open(output_file, \"wb\") as f_out:\n",
    "    pickle.dump((dv, model), f_out)\n",
    "    # do stuff\n",
    "    \n",
    "# do other stuff (file is closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884047db-bf26-4ae0-b4ee-f6b03fc22469",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "\n",
    "* Restart the kernel to pretend we are in a new process, that doesn't know the previous variables\n",
    "* sklearn does not need to be imported, but needs to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18de7e74-44a1-47b3-80c2-3911719ab33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b596306d-af6f-40b3-aa3f-4e1c14dee23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"model_C=1.0.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66595dd-5244-4ed8-ab1d-12a0b267a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_file, \"rb\") as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ce6bb9-e1b6-4efe-bd38-2cf1ec57cd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(sparse=False), LogisticRegression(max_iter=1000))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441df18a-e66d-460e-800a-29a788ea971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = {\n",
    "    \"gender\": \"female\",\n",
    "    \"seniorcitizen\": 0,\n",
    "    \"partner\": \"yes\",\n",
    "    \"dependents\": \"no\",\n",
    "    \"phoneservice\": \"no\",\n",
    "    \"multiplelines\": \"no_phone_service\",\n",
    "    \"internetservice\": \"dsl\",\n",
    "    \"onlinesecurity\": \"no\",\n",
    "    \"deviceprotection\": \"no\",\n",
    "    \"techsupport\": \"no\",\n",
    "    \"streamingtv\": \"no\",\n",
    "    \"streamingmovies\": \"no\",\n",
    "    \"contract\": \"month-to-month\",\n",
    "    \"paperlessbilling\": \"yes\",\n",
    "    \"paymentmethod\": \"electronic_check\",\n",
    "    \"tenure\": 1,\n",
    "    \"monthlycharges\": 29.85,\n",
    "    \"totalcharges\": 29.85\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c66a532-1ed8-4713-b310-3db679534a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn this customer into a feature matrix\n",
    "X = dv.transform([customer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "267ab111-8f8e-4f07-bbac-d89c64092d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6638191204255028"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilty that this customer churns\n",
    "model.predict_proba(X)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462113ce-d9a2-463b-b28e-e940554431cb",
   "metadata": {},
   "source": [
    "* This is how a model can be saved and used later for prediction\n",
    "* However, it is not convinient to do this all in a jupyter notebook\n",
    "* Create a single .py file that does all this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91eb91-1f87-4ab9-8346-dbed03b8b03b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Web Services: Introduction to Flask\n",
    "\n",
    "**What is a web service?**\n",
    "* Web services method to communicate between two devices over a network\n",
    "* E.g. \"Google\" is a web service\n",
    "\n",
    "**How to use it:**\n",
    "* Use flask to implement the web service\n",
    "    * Write a python function\n",
    "    * Turn it into a web service\n",
    "    * Access this function from the terminal or the browser\n",
    "\n",
    "**Example:**\n",
    "* Writing a simple ping/pong app (saved in ping.py)\n",
    "* Querying it with \"curl\" (command line utilty to communicate with web services) and browser\n",
    "    * curl http://0.0.0.0:9696 or curl http://localhost:9696/ping\n",
    "    * in browser: http://localhost:9696/ping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e7757-39bb-432a-b055-7b917a450fee",
   "metadata": {},
   "source": [
    "## Serving the Churn Model with Flask\n",
    "\n",
    "* Wrapping the predict script into a Flask app\n",
    "    * Cretae a web service (Churn Service) for our model\n",
    "    * This should live in \"/predict\"\n",
    "    * Information is send in JSON and response is also in JSON\n",
    "        * Create JSON file for customer information\n",
    "* Querying it with \"requests\"\n",
    "    * Using the web service from the browser is this time not possible, because we used the \"POST\" method\n",
    "* Example saved in predict_flask.py\n",
    "    * For debug mode run in terminal ```python predict_flask.py``` (we set \"debug=True\")\n",
    "    * This is only for developing, for production we need to use something else, but not plain Flask, e.g. gunicorn\n",
    "    * Use Flask app for production:```gunicorn --bind 0.0.0.0:9696 predict:app ``` (in terminal)\n",
    "* Preparing for production: gunicorn\n",
    "* Running it on Windows with waitress (gunicorn is not supprted by windows)\n",
    "    * ```waitress-serve --listen=0.0.0.0:9696 predict:app```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278b75c-c7db-4b34-b470-527479063b2d",
   "metadata": {},
   "source": [
    "## Dependency and Environment Management: Pipenv\n",
    "\n",
    "* Why we need virtual environments\n",
    "    * If we have more than one application, they may depend on different versions of a package\n",
    "    * The dependencies of all packages for an application must be ensured\n",
    "    \n",
    "![screenshot](Screenshot_2.png)\n",
    "* There are different ways to use vitual environment\n",
    "    * virtual env / venv\n",
    "    * conda\n",
    "    * pipenv -> used in this lesson\n",
    "    * poetry\n",
    "* Installing Pipenv\n",
    "    * ```pip install pipenv```\n",
    "* Installing libraries with Pipenv\n",
    "    * ```pipenv install numpy pandas scikit-learon=0.24.2 flask```\n",
    "    * ```pipenv install gunicorn```\n",
    "    * This creates two new files: ```Pipfile```, ```Pipfile.lock```\n",
    "    * Pipfile contains the packages we installed\n",
    "    * Pipfile.lock is a JSON dictionary, that specifiees the exact version of the packeges we installed\n",
    "        * When we want to work with someone together, we only need to give her the Pipenv and Pipenv.lock file, then she can do ```pipenv install``` and all dependencies will be installed as in the ```Pipfile```.\n",
    "* Running things with Pipenv\n",
    "* To activate the virtual envronment: ```pipenv shell``` (shows which subfolders are used for this virtual environment)\n",
    "* To exit the environment, type ```exit```\n",
    "* To check which library is used type, e.g. ```which numpy```\n",
    "* As abbreviation, to run somethin in the virtual environment, we can use ```pipenv run <command>```, e.g. ```pipenv run --bind 0.0.0.0:9696 predict_flask:app```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6834494-0993-492c-b270-1a494ee4e632",
   "metadata": {},
   "source": [
    "## Environment Management: Docker\n",
    "\n",
    "* Why we need docker\n",
    "    * Virtual environments only can separate different Python versions and libraries, but they are still on the same system\n",
    "    * Different applications may also have different system dependencies -> For this we need Docker\n",
    "    * With docker we can isolate our application from the rest that is on our computer\n",
    "    * Instead of creating virtual environments, we put every application in different container\n",
    "![screenshot docker](Screenshot_3.png)\n",
    "\n",
    "    * We can then take such a container and deply it on the cloud\n",
    "\n",
    "* Running a Python Image with docker\n",
    "    * Go to docker.hub\n",
    "\n",
    "![screenshot docker python](Screenshot_4.png)\n",
    "![screenshot docker tags](Screenshot_5.png)\n",
    "     \n",
    "* We use Pythom 3.8 slim: use the tag ```3.8.12-slim```\n",
    "* Run the image with ```docker run -it --rm python:3.8.12-slim```\n",
    "    * ```-it``` means that we have access to the terminal\n",
    "    * ```--rm``` removes the image after using it\n",
    "* To start the docker daemon: ```sudo service docker start```\n",
    "* The we can use Python, e.g. ```print(\"Hello World!\")\n",
    "* We we execute the previous command, the default entrypoint in Python. We can change this to get into the environment, e.g. ```docker run -it --rm entrypoint=bash python:3.8.12-slim```. Then we can a terminal, which we can use for .g. installing. We can`e.g. run ```apt-get update```, ```apt-get install wget``, etc.\n",
    "        * Everything we do in this container, stays in it. We can also use pipenv: ```pip install pipenv``` or create a directory, etc.\n",
    "* Dockerfile\n",
    "    * We use a Dockerfile to define everything we want to do in a docker container\n",
    "    * First the base image needs to be defined and then what we want to do or install on the conatiner,\n",
    "    e.g. install pipenv and copy Pipfile and Pipfile.dock\n",
    "* Building a docker image\n",
    "    * To build the image use: ```docker build -t zoomcamp-test .```\n",
    "    * The ```.``` means: use the Dockerfile from the current directory\n",
    "* Running a docker image\n",
    "    * Run the image: ```sudo docker run -t --rm zoomcamp-test```\n",
    "    * We could now install a virtual environment in the docker container, but we will directly do this in the Dockerfile\n",
    "    * Since Docker is already isolated, we don't really need an extra virtual environment\n",
    "    * We can use ```--system``` to install the libraries directly on the system\n",
    "    * Add ```RUN pipenv install --system --deploy``` to the Dockerfile\n",
    "    * Also copy the python script and the model we need to the container: ```COPY [\"predict_flask.py\", \"model_C=1.0.bin\", \"./\"]```\n",
    "    * We buid the image again and run it, then we can execute within the conatainer: ```gunicorn --bind 0.0.0.0:9696 predict_flask:app```\n",
    "    * The port cannot be executed yet, it needs to be maped to the host machine\n",
    "    * Also the entrypoint can be defined within the Dockerfile, the we don't need to specify it when running the image ```ENTRYPOINT [\"gunicorn\", \"--bind 0.0.0.0:9696\", \"predict_flask:app\"]```\n",
    "    * In order to connect to the port we need to run the image using: ```docker run -it --rm -p 9696:9696 zoomcamp-test```. This maps the port 9696 on the container to the port 9696 of the host machine.\n",
    "    * Now we can run ```predict-test.py``` a different tab.\n",
    "![screenshot map port](Screenshot_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9474314-b65d-4aab-9e61-ea04efa2f018",
   "metadata": {},
   "source": [
    "## Deploying to the Cloud: AWS Elastic Beanstalk (optional)\n",
    "\n",
    "* Installing the eb cli\n",
    "* Running eb locally\n",
    "* Deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6494199-2ce0-42eb-bddb-9273ea92031b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdf94500-a01c-441a-998d-196b724f29d5",
   "metadata": {},
   "source": [
    "## Explore More\n",
    "\n",
    "* Flask is not the only framework for creating web services. Try others, e.g. FastAPI\n",
    "* Experiment with other ways of managing environments, e.g., virtual env, conda,  poetry\n",
    "* Explore other ways of deploying web services, e.g. GCP, Azure, Heroku, Python Anywhere, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d984a6-4469-4ddb-a0d1-781bfb2c1c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53f52c3d-c18d-4213-af58-ebf4193628da",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78866aa-9ba2-427f-871a-64e8aafb65e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "ml-zoomcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
