{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afafea53",
   "metadata": {},
   "source": [
    "# Tensorflow Serving\n",
    "\n",
    "* Context: clothing prediction\n",
    "* tf serving is especially created for serving tf models\n",
    "* a library written in C++\n",
    "* is only for inference\n",
    "* gets the already preprocessed data (image)\n",
    "* we need to create a \"Gateway\" that does the preprocessing\n",
    "\n",
    "![workflow](Screenshot_01.png)\n",
    "\n",
    "* For the gateway we will use Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca1d13",
   "metadata": {},
   "source": [
    "## TensorFlow Serving\n",
    "\n",
    "* Convert our trained model to the format of tf serving (saved_model format)\n",
    "* Run TF-Serving locally using docker\n",
    "* Invoking the model from Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3b30e",
   "metadata": {},
   "source": [
    "Use a model from week8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2ffc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea9593a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f6dcc4b2d00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path =\"../week8\"\n",
    "model = keras.models.load_model(os.path.join(path, \"xception_v4_05_0.850.h5\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98025263",
   "metadata": {},
   "source": [
    "Save the model in required format for tf-serving. This creates a folder 'clothing_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c0acba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clothing-model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'clothing-model') # model, folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b32bcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2,7M\r\n",
      "drwxr-xr-x 2 frauke frauke 4,0K Mai  6 07:27 variables\r\n",
      "-rw-rw-r-- 1 frauke frauke 2,7M Mai  6 07:27 saved_model.pb\r\n",
      "drwxr-xr-x 2 frauke frauke 4,0K Mai  6 07:27 assets\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lrh clothing-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "757dca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mclothing-model\u001b[00m\r\n",
      "├── \u001b[01;34massets\u001b[00m\r\n",
      "├── saved_model.pb\r\n",
      "└── \u001b[01;34mvariables\u001b[00m\r\n",
      "    ├── variables.data-00000-of-00001\r\n",
      "    └── variables.index\r\n",
      "\r\n",
      "2 directories, 3 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree clothing-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7b7b5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothing-model:\r\n",
      "total 2,7M\r\n",
      "drwxr-xr-x 2 frauke frauke 4,0K Mai  6 07:27 assets\r\n",
      "-rw-rw-r-- 1 frauke frauke 2,7M Mai  6 07:27 saved_model.pb\r\n",
      "drwxr-xr-x 2 frauke frauke 4,0K Mai  6 07:27 variables\r\n",
      "\r\n",
      "clothing-model/assets:\r\n",
      "total 0\r\n",
      "\r\n",
      "clothing-model/variables:\r\n",
      "total 83M\r\n",
      "-rw-rw-r-- 1 frauke frauke 83M Mai  6 07:27 variables.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 frauke frauke 15K Mai  6 07:27 variables.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lRh clothing-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a37b0d18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-06 07:27:40.333914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-06 07:27:40.333937: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_13'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 299, 299, 3)\n",
      "        name: serving_default_input_13:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_7'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Concrete Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_13: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_13')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_13: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_13')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_13: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_13')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_13: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_13')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_13: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_13')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir clothing-model --all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489953ac",
   "metadata": {},
   "source": [
    "* We are interested in ```signature_def['serving_default']``` -> save names of input and output in ```model-description.txt```\n",
    "* Now use docker to run tf-serving locally using this model:\n",
    "    * We use the official image from tensorflow\n",
    "    * ```\n",
    "       docker run -it --rm \\ \n",
    "       -p 8500:8500 \\\n",
    "       -v \"$(pdw)/clothing-model:/models/clothing-model/1\" \\\n",
    "       -e MODEL_NAME=\"clothing-model\" \\\n",
    "       tensorflow/serving:2.7.0\n",
    "       ```\n",
    "    * the image maps port 8500\n",
    "    * we are mounting a \"volume\" - the model folder\n",
    "    * the name of this folder has to be the same as the ```MODEL_NAME```\n",
    "    * ```tensorflow/serving:2.7.0``` is the image name\n",
    " * Now send something to this model: code in notebook ```tf-serving-connect.ipynb```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e385720a",
   "metadata": {},
   "source": [
    "## Creating a Preprocessing Service\n",
    "\n",
    "* Convert the notebook to a python script\n",
    "    * ```jupyter nbconvert tf-serving.ipynb --to script```\n",
    "    * rename it and call it ```gateway.py```\n",
    "* wrap the script into a flask app\n",
    "    * run ```gateway.py``` in terminal\n",
    "    * test it in another terminal with ```test.py```\n",
    "* Put everything into Pipenv\n",
    "    * ```pipenv install grpcio==1.42.0 flask gunicorn keras-image-helper```\n",
    "    * Not installing tf and tf-serving. tf is a big library, which we do not want to have in our code, we only need ```make_tensor_proto``` from tf. We will therefore only install ```tensorflow-protobuf=2.7.0```: ```pipenv install tensorflow-protobuf==2.7.0```\n",
    "    * The code then needs to be adapted. Create ```proto.py``` to convert a tensor into a protobuf data type (https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/10-kubernetes/code/proto.py)\n",
    "    * Start virtual environment with ```pipenv shell```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c30d9f",
   "metadata": {},
   "source": [
    "## Run everything locally with Docker-Compose\n",
    "\n",
    "* Run tf-serving model and gateway service together with docker-compose\n",
    "* Prepare the docker images\n",
    "    * Previously we used the oficial image from tensorflow\n",
    "    * This does not contain the model\n",
    "    * create a dockerfile: ```image-model.dockerfile```\n",
    "    * ```docker build -t zoomcamp-10-model:exception -f image-model.dockerfile .```\n",
    "    * Here ```-f``` specifies the filename, because we didn't call it ```Dockerfile```\n",
    "    * ```docker run -it --rm -p 8500:8500 zoomcamp-10-model:exception```\n",
    "    * Now we can run ```gateway.py``` in another terminal\n",
    "    * Now we have an image for tf-serving our model, now need to do the same for our gateway service\n",
    "    * Creat another image: ```image-gateway.dockerfile```, analogue to Lecture 5\n",
    "    * ```docker build -tzoomcamp-10-gateway:001 -f image-gateway.dockerfile .```\n",
    "    * ```docker run -it -p 9696:9696 --rm zoomcamp-10-gateway:001```\n",
    "    * Now we have the model and the gateway running in two different terminals, test it in aother terminal ```python3 test.py```. This is not working. The gateway cannot connect to tf-serving\n",
    "    \n",
    "    ![overview](Screenshot_02.png)\n",
    "    \n",
    "    * We have to link the two services.\n",
    "    * For that they have to live in the same network.\n",
    "    * In order to do this, we will use docker-compose\n",
    "* Install docker-compose (to run two services on one machine)\n",
    "    * Follow instructions from here: https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-compose-on-ubuntu-20-04-de\n",
    "    * Add it to our ```PATH```: In ```.bashrc``` add the line export ```PATH=\"${HOME}/usr/local/bin/docker-compose:${PATH}\"```\n",
    "    * ```source .bashrc``` \n",
    "    * ```echo $PATH``` returns: ```/home/frauke/usr/local/bin/docker-compose:/home/frauke/usr/local/bin/docker-compose:/home/frauke/anaconda3/bin:/home/frauke/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin```\n",
    "    * ```which docker-compose``` returns: ```/usr/local/bin/docker-compose```\n",
    "    * Create a docker-compose file: ```docker-compose.yaml```\n",
    "    * At the moment flask uses ```localhost:8500```, we need to change that to os.getenv(\"TF_SERVING_HOST\", \"localhost:8500\").\n",
    "    * Now localhot is only used if \"TF_SERVING_HOST\" is not set\n",
    "    * rebuild the image: ```docker build -t zoomcamp-10-gateway:002 -f image-gateway.dockerfile .```\n",
    "* Run the service\n",
    "    * ```docker-compose up``` looks for the docker-compose.yaml file in this directory\n",
    "* Test the service (Take care of the right version on the top of the docker-compose.yaml!)\n",
    "    * run ```test.py``` in different terminal\n",
    "    * ```docker-compose up -d``` runs docker-compose in detach mode, i.e. we can keep working in the same terminal\n",
    "    * use ```docker-compose down``` to terminate docker-compose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd97ad",
   "metadata": {},
   "source": [
    "## Introduction to Kubernetes\n",
    "\n",
    "* \" Kubernetes groups containers that make up an application into logical units for easy management and discovery\"\n",
    "    * Kubernetes can be used to deploy and manage docker images\n",
    "    * Creates more instances if there is high traffic and remove them, when there is low traffic\n",
    "    * We can deploy docker images to the cloud using Kubernetes\n",
    "* The anatomy of a Kubernetes cluster\n",
    "![anatomy](Screenshot_03.png)\n",
    "![explanations](Screenshot_04.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f979bee",
   "metadata": {},
   "source": [
    "## Deploy a simple service to Kubernetes\n",
    "\n",
    "* Create a simple ping - png application in Flask\n",
    "    * Create a virtuel environment and install flask and gunicorn\n",
    "    * ```pipenv install flask gunicorn```\n",
    "    * Note: In this case there is already a Pipfile in the parent directory where it is tried to be installed. In order to get  a fresh virtual environment, we need to create an empty ```Pipfile``` (```touch Pipfile```) first and then run the installation command\n",
    "    * Now we need to create a dockerfile for this application (Adapt the Dockerfile from Week 5)\n",
    "    * Build the inage: ```docker build -t ping:v001 .```\n",
    "    * Run the image: ```docker run -it --rm -p 9696:9696 ping:v001```\n",
    "    * Test it in terminal with ```curl localhost:9696/ping``` and the terminal should output ```PONG```\n",
    "    \n",
    "* Install kunectl (ttps://kubernetes.io/de/docs/tasks/tools/install-kubectl/)\n",
    "    * command line program to provide and manage applications in Kubernetes\n",
    "    * With kubectl we can check cluster resources \n",
    "    * We can create, delete and update components\n",
    "    * Either install from the above website:\n",
    "        ```sudo apt-get update && sudo apt-get install -y apt-transport-https\n",
    "           curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "           echo \"deb https://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee -a /etc/apt/sources.list.d/kubernetes.list\n",
    "           sudo apt-get update\n",
    "           sudo apt-get install -y kubectl\n",
    "        \n",
    "        ```\n",
    "    * Or from AWS. Which we will do, because later we want to deploy the application on AWS: https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html\n",
    "      ```\n",
    "      curl -o kubectl https://s3.us-west-2.amazonaws.com/amazon-eks/1.22.6/2022-03-09/bin/linux/amd64/kubectl\n",
    "      ```\n",
    "    * First create a folder ```bin``` in our home directory and execute the above command there. Then add this folder to our ```PATH``` by adding (```export PATH=\"${HOME}/bin:${PATH}\"``` to the ```.bashrc```\n",
    "    * Then make the file executable: ```chmod +x kubectl```\n",
    "    * Note: In the lecture this has already be done when docker-combose was installed, then we don't need to add another ```PATH```\n",
    "    * Test if the installation worked: Go back to the ```HOME``` folder and type ```kubectl```\n",
    "* Set up a local Kubernetes cluster with Kind (Tool for setting up a local Kubernetes Cluster)\n",
    "    * Install Kind to the same directory (```/bin```): https://kind.sigs.k8s.io/docs/user/quick-start/#installation\n",
    "    * ```\n",
    "        curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.12.0/kind-linux-amd64\n",
    "chmod +x ./kind\n",
    "      ```\n",
    "* Create a Deployment\n",
    "    * Now we have to create a cluster. Go back to the folder ```..../ping```\n",
    "    * Type ```kind create cluster```\n",
    "        * Creating cluster \"kind\"\n",
    "    * Now we need to configure our kubectl, so that it knows that it has to access ```kind-kind``` by typing: ```kubectl cluster-info --context kind-kind```\n",
    "    * Check if it is working: ```kubectl get service```. Outputs all the services:\n",
    "    \n",
    "    |NAME|TYPE|CLUSTER-IP|EXTERNAL-IP|PORT(S)|AGE|\n",
    "    |----|----|----------|-----------|-------|---|\n",
    "    |kubernetes|ClusterIP|10.96.0.1|<none>|443/TCP|117s|\n",
    "    \n",
    "    ```kubectl get pod``` -> outout: ```No resources found in default namespace.```\n",
    "    ```kubectl get deployment``` -> output: ```No resources found in default namespace.```\n",
    "\n",
    "    * Now we have to create an deployment.yml file for kubernetes\n",
    "    ```\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    metadata: ## deployment name\n",
    "      name: ping-deployment\n",
    "    spec:\n",
    "      replicas: 1 # nr of replicas\n",
    "      selector:\n",
    "        matchLabels: # all pods with label=\"ping\" belong to this deployment\n",
    "          app: ping\n",
    "      template: ## template for pods\n",
    "        metadata:\n",
    "          labels:\n",
    "            app: ping # each pot gets label app=\"ping\"\n",
    "        spec: ## ~ pod name\n",
    "          containers:\n",
    "          - name: ping-pod # name of the container\n",
    "            image: ping:v001\n",
    "            resources: ## how much resources do we give to this pod\n",
    "              limits:\n",
    "                memory: \"128Mi\"\n",
    "                cpu: \"200m\" ## not more than 20% of the cpus should be used\n",
    "            ports: ## port to expose\n",
    "            - containerPort: 9696\n",
    "    ```\n",
    "    \n",
    "    * Apply this config file to our Kubernetes cluster: ```kubectl apply -f deployment.yaml``` (the option ```-f``` means: read from file)\n",
    "    * output: ```deployment.apps/ping-deployment created```\n",
    "    * ```kubectl get deployment``` now outputs \n",
    "    |NAME|READY|UP-TO-DATE|AVAILABLE|AGE|\n",
    "    |----|-----|----------|---------|---|\n",
    "    |ping-deployment|0/1|1|0 |73s|\n",
    "\n",
    "    * ```kube ctl get pod``` outputs\n",
    "    \n",
    "    |NAME|READY|STATUS|RESTARTS|AGE|\n",
    "    |----|-----|------|--------|---|\n",
    "    |ping-deployment-6988b67698-7qmp6|0/1|ImagePullBackOff|0|5m3s|\n",
    "    * To see more details: ```kubectl describe pod ping-deployment-6988b67698-7qmp6|less\n",
    "```\n",
    "    * This shows the error message:\n",
    "    ```\n",
    "    Failed to pull image \"ping:v001\": rpc error: code = Unknown desc = failed to pull and unpack image \"docker.io/library/ping:v001\": failed to resolve reference \"docker.io/library/ping:v001\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed\n",
    "```\n",
    "        * This happens, because we didn't tell Kind that this image should be registered in Kubernetes, i.e. we have to load the image to the cluster: ```kind load docker-image ping:v001```\n",
    "    * Now ```kubectl get pod``` outputs\n",
    "   |NAME|READY|STATUS|RESTARTS|AGE|\n",
    "   |----|-----|------|--------|---|\n",
    "   |ping-deployment-6988b67698-7qmp6|1/1|Running|0|13m|\n",
    "      \n",
    "    * Test the deployment\n",
    "    ![test deployment](Screenshot_05.png)   \n",
    "    \n",
    "    * ```kubectl port-forward ping-deployment-6988b67698-7qmp6 9696:9696```, then in another terminal test it. Type: ```curl localhost:9696/ping```, the response should be ```PONG```\n",
    "* Create a service: ```service.yaml```\n",
    "    ```\n",
    "    apiVersion: v1\n",
    "        kind: Service\n",
    "        metadata:\n",
    "          name: ping # name of the service\n",
    "        spec:\n",
    "          type: LoadBalancer\n",
    "          selector: # which pods qualify for forwarding requests\n",
    "            app: ping\n",
    "          ports:\n",
    "          - port: 80\n",
    "            targetPort: 9696 # port on the pod\n",
    "    ```\n",
    "    * Use ```kubectl apply -f service.yaml```, output: ```service/ping created```\n",
    "    * ```kubectl get service``` outputs\n",
    "    |NAME|TYPE|CLUSTER-IP|EXTERNAL-IP|PORT(S)|AGE|\n",
    "    |----|----|----------|-----------|-------|---|\n",
    "    |kubernetes|ClusterIP|10.96.0.1|<none>|443/TCP|22h|\n",
    "    |ping|LoadBalancer|10.96.27.142|<pending>|80:31793/TCP|68s|\n",
    "    * Now do the port-forwarding for the service: ```kubectl port-forward service/ping 8080:80```\n",
    "    * Test in another terminal: ```curl localhost:8080/ping```\n",
    "    * To delete a deployment: ```kubectl delete -f deployment```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3409b",
   "metadata": {},
   "source": [
    "# Deploy Tensorflow Models to Kubernetes\n",
    "\n",
    "* We already deployed a service in the previous section\n",
    "* Use ```kubectl get pod``` to see which pods are running and ```kubectl get deployment``` to see the deployments\n",
    "* Previously we created a docker-compose file to run both the model and the gateway, now we want to replicate this, but deploy it to Kubernetes\n",
    "\n",
    "* Deploy the tf-serving model  \n",
    "    * create a file ```model-deployment.yaml```\n",
    "    * make the image used available for kind: ```kind load docker-image zoomcamp-10-model:exception```\n",
    "    * Create deployment: ```kubectl apply -f model-deployment.yaml```\n",
    "    * ```kubectl get pod``` now shows the new deployment\n",
    "    * test it:\n",
    "        * ```kubectl port-forward tf-serving-clothing-model-88ff9bcfb-nfsg4 8500:8500```\n",
    "        * Now use gateway.py for testing (without flask). ```python gateway.py``` in a different terminal should now give the predictions\n",
    "    * Create a service: ```model-service.yaml```\n",
    "    * ```kubectl apply -f model-service.yaml```\n",
    "    * ```kubectl get service``` to see all services\n",
    "    * forward the port for the service ```kubectl port-forward service/tf-serving-clothing-model 8500:8500```\n",
    "* Deploy the gateway\n",
    "    * Create a file ```gateway-deployment.yaml```\n",
    "    * ```kind load docker-image zoomcamp-10-gateway:002```\n",
    "    * Additionally to the model deployment file, here we also need to set the environment variable, which we set in the docker file. The urls follow the following naming: ```<NAME>.default.svc.cluster.local:8500```, in our case ```<NAME>=tf-serving-model```\n",
    "* Test the service\n",
    "    * Log in to a pod and execute the ```bash``` command: ```kubectl exec -it ping-deployment-5964c9c9cc-cxf7v -- bash```\n",
    "    * Now we want to access the service (tf-serving-clothing-model) using the url: ```curl localhost:9696/ping```\n",
    "    * But first we need to install ```curl```:```apt update```, ```apt install curl```\n",
    "    * Then ```curl localhost:9696/ping``` replies with ```PONG``` (this is running a request within the container)\n",
    "    * Test the service: ```curl ping.default.svc.cluster.local/ping```. This sends a request to the service (running on port 80, which is the default) and the service sends it back to our container. (The above command does the same as: ```curl ping.default.svc.cluster.local:80/ping```\n",
    "    * Test the tf-serving-clothing-model\n",
    "        * tf does not allow curl requests, we will use telnet\n",
    "        * ```apt install telnet```\n",
    "        * ```telnet tf-serving-clothing-model.default.svc.cluster.local 8500```, this allows us to send something to the port. This is just for testing if the connection works.\n",
    "* Create the gateway deployment\n",
    "    * ```kubectl apply -f gateway-deployment.yaml``` \n",
    "    * Forward the port from the gateway deployment to our host machine and execute a command: ```kubectl port-forward gateway-56dd4c97-x5vbq 9696:9696```\n",
    "    * Then in a different terminal execute ```test.py```\n",
    "* Create gateway service\n",
    "    * create ```gateway-service.yaml```\n",
    "    * ```kubectl apply -f gateway-service.yaml```\n",
    "    * Port forward from the service to our localhost for testing: ```kubectl port-forward service/gateway 8080:80```\n",
    "    * Use ```test.py``` to test the service, note the port in test.py has to be changes to 8080!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e0317",
   "metadata": {},
   "source": [
    "## Deploy to EKS\n",
    "\n",
    "* No we deploy the previously created .yaml files to a EKS cluster on AWS\n",
    "* Create a EKS cluster on AWS\n",
    "    * use eksctl for that\n",
    "    * Download it to our ```\\bin``` folder we created\n",
    "    * ```wget \"https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\" | tar xz -C /tmp``` (Link from https://docs.aws.amazon.com/eks/latest/userguide/eksctl.html)\n",
    "    * Extract the file: ```tar xzfv eksctl_Linux_amd64.tar.gz```\n",
    "    * Now we can create a EKS cluster: ```eksctl create --name ml-zoomcamp-eks```\n",
    "    * We will save this in a configuration file:\n",
    "        ```\n",
    "        apiVersion: eksctl.io/v1alpha5\n",
    "        kind: ClusterConfig\n",
    "\n",
    "        metadata:\n",
    "          name: mlzoomcamp-eks\n",
    "          region: eu-west-1\n",
    "\n",
    "        nodeGroups: # nodes within a group will all have the same configuration\n",
    "          - name: ng-m5-xlarge\n",
    "            instanceType: m5.xlarge\n",
    "            desiredCapacity: 1\n",
    "\n",
    "        ```\n",
    "        * Now we create the cluster from the config: ```eksctl create cluster -f eks-config.yaml```\n",
    "* Publish the image to ECR\n",
    "    * ```aws ecr create repository --repository-name ml-zoomcamp-images```\n",
    "    * ```\n",
    "    ACCOUNT_ID=387546586013\n",
    "    REGION=eu-west-1\n",
    "    REGISTRY_NAME=mlzoomcamp-images\n",
    "    PREFIX=${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com/${REGISTRY_NAME}\n",
    "\n",
    "    GATEWAY_LOCAL=zoomcamp-10-gateway:002\n",
    "    GATEWAY_REMOTE=${PREFIX}:zoomcamp-10-gateway-002\n",
    "    docker tag ${GATEWAY_LOCAL} ${GATEWAY_REMOTE}\n",
    "\n",
    "    MODEL_LOCAL=zoomcamp-10-model:exception\n",
    "    MODEL_REMOTE=${PREFIX}:zoomcamp-10-model-exception\n",
    "    docker tag ${GATEWAY_LOCAL} ${GATEWAY_REMOTE}\n",
    "    ```\n",
    "    * Now push the images:\n",
    "        * login to ecr: ```$(aws ecr get login --no-include-email)```\n",
    "        * push the images: ```docker push ${MODEL_REMOTE}```, ```docker push ${GATEWAY_REMOTE}```\n",
    "* Configure kubectl\n",
    "    * When the cluster is created ... (This may take some time)\n",
    "    * Apply the config files: ```kubectl apply -f model-deployment.yaml```, ```kubectl apply -f model-service.yaml```\n",
    "    * Now we forward the port. This time not from our local port, but from a remote port.\n",
    "        ```kucectl port-forward service/tf-serving-clothing-model 8500:8500```\n",
    "    * Test with ```python gateway.py```\n",
    "    * Apply the config files: ```kubectl apply -f gateway-deployment.yaml```, ```kubectl apply -f gateway-service.yaml```\n",
    "    * Test with ```python test.py```, change url to the one we see in ```kubectl get service``` (should be a long url)\n",
    "* At the moment this is open to everyone, extra care has to be taken to restrict the access.\n",
    "* Delete the cluster ```eksctl delete cluster --name ml-zoomcamp-eks```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a823662",
   "metadata": {},
   "source": [
    "## Explore More\n",
    "\n",
    "* Other local Kubernetes: minikube, k3d, k3s, mikrok8s, EKS Anywhere\n",
    "* [Rancher Desktop](https://rancherdesktop.io)\n",
    "* Docker desktop\n",
    "* [Lens](https://k8slens.dev)\n",
    "* Many cloud provider have Kubernetes: GPC, Azure, Digital Ocean, and others. Search for \"Managed Kubenetes\".\n",
    "* Deploy the model from the previous modules and from your project with kubernetes\n",
    "* Lear about Kubernetes Namespaces. Here we used the default namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e305c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
